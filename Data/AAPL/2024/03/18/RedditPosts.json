[
    {
        "title": "Nvidia announces Blackwell AI chips that will launch later this year",
        "score": 1221,
        "url": "https://www.reddit.com/r/stocks/comments/1bi129l/nvidia_announces_blackwell_ai_chips_that_will/",
        "content": "Nvidia on Monday announced a new generation of artificial intelligence chips and software for running AI models. The announcement, made during Nvidia’s developer’s conference in San Jose, comes as the chipmaker seeks to solidify its position as the go-to supplier for AI companies.\n\nNvidia’s share price is up five-fold and total sales have more than tripled since OpenAI’s ChatGPT kicked off the AI boom in late 2022. Nvidia’s high-end server GPUs are essential for training and deploying large AI models. Companies like Microsoft and Meta have spent billions of dollars buying the chips.\n\nThe new generation of AI graphics processors is named Blackwell. The first Blackwell chip is called the GB200 and will ship later this year. Nvidia is enticing its customers with more powerful chips to spur new orders. Companies and software makers, for example, are still scrambling to get their hands on the current generation of H100s and similar chips.\n\n“Hopper is fantastic, but we need bigger GPUs,” Nvidia CEO Jensen Huang said on Monday at the company’s developer conference in San Jose, California. “Let me introduce you to a very big GPU.”\n\nThe company also introduced revenue-generating software called NIM that will make it easier to deploy AI, giving customers another reason to stick with Nvidia chips over a rising field of competitors.\n\nNvidia executives say that the company is becoming less of a mercenary chip provider and more of a platform provider, like Microsoft or Apple, on which other companies can build software.\n\n“The sellable commercial product was the GPU and the software was all to help people use the GPU in different ways,” said Nvidia enterprise VP Manuvir Das in an interview. “Of course, we still do that. But what’s really changed is, we really have a commercial software business now.”\n\nDas said Nvidia’s new software will make it easier to run programs on any of Nvidia’s GPUs, even older ones that might be better suited for deploying but not building AI.\n\n“If you’re a developer, you’ve got an interesting model you want people to adopt, if you put it in a NIM, we’ll make sure that it’s runnable on all our GPUs, so you reach a lot of people,” Das said.\n\nEvery two years Nvidia updates its GPU architecture, unlocking a big jump in performance. Many of the AI models released over the past year were trained on the company’s Hopper architecture — used by chips such as the H100 — which was announced in 2022.\n\nNvidia says Blackwell-based processors, like the GB200, offer a huge performance upgrade for AI companies, with 20 petaflops in AI performance versus 4 petaflops for the H100. The additional processing power will enable AI companies to train bigger and more intricate models, Nvidia said.\n\nThe chip includes what Nvidia calls a “transformer engine specifically built to run transformers-based AI, one of the core technologies underpinning ChatGPT.\n\nThe Blackwell GPU is large and combines two separately manufactured dies into one chip manufactured by TSMC. It will also be available as an entire server called the GB200 NVLink 2, combining 72 Blackwell GPUs and other Nvidia parts designed to train AI models.\n\nAmazon, Google, Microsoft, and Oracle will sell access to the GB200 through cloud services. The GB200 pairs two B200 Blackwell GPUs with one Arm-based Grace CPU. Nvidia said Amazon Web Services would build a server cluster with 20,000 GB200 chips.\n\nNvidia said that the system can deploy a 27-trillion-parameter model. That’s much larger than even the biggest models, such as GPT-4, which reportedly has 1.7 trillion parameters. Many artificial intelligence researchers believe bigger models with more parameters and data could unlock new capabilities.\n\nNvidia didn’t provide a cost for the new GB200 or the systems it’s used in. Nvidia’s Hopper-based H100 costs between $25,000 and $40,000 per chip, with whole systems that cost as much as $200,000, according to analyst estimates.\n\nNvidia also announced it’s adding a new product named NIM to its Nvidia enterprise software subscription.\n\nNIM makes it easier to use older Nvidia GPUs for inference, or the process of running AI software, and will allow companies to continue to use the hundreds of millions of Nvidia GPUs they already own. Inference requires less computational power than the initial training of a new AI model. NIM enables companies that want to run their own AI models, instead of buying access to AI results as a service from companies like OpenAI.\n\nThe strategy is to get customers who buy Nvidia-based servers to sign up for Nvidia enterprise, which costs $4,500 per GPU per year for a license.\n\nNvidia will work with AI companies like Microsoft or Hugging Face to ensure their AI models are tuned to run on all compatible Nvidia chips. Then, using a NIM, developers can efficiently run the model on their own servers or cloud-based Nvidia servers without a lengthy configuration process.\n\n“In my code, where I was calling into OpenAI, I will replace one line of code to point it to this NIM that I got from Nvidia instead,” Das said.\n\nNvidia says the software will also help AI run on GPU-equipped laptops, instead of on servers in the cloud.\n\nSource: https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html",
        "created_utc": 1710793879.0,
        "subreddit_name": "stocks",
        "comments": 255
    },
    {
        "title": "Apple might use Google Gemini to power some AI features on the iPhone",
        "score": 515,
        "url": "https://www.reddit.com/r/stocks/comments/1bhofi6/apple_might_use_google_gemini_to_power_some_ai/",
        "content": "https://9to5google.com/2024/03/17/gemini-apple-iphone-talks/\n\nAccording to Bloomberg, there are “active negotiations to let Apple license Gemini, Google’s set of generative AI models, to power some new features coming to the iPhone software this year.” Apple has also talked with OpenAI, which powers Microsoft’s AI capabilities.\nApple is specifically looking to partner on cloud-based generative AI, with today’s report citing text and image generation as examples of what Gemini could be used for. At the same time, Apple is working on offering its own on-device AI models and capabilities with the upcoming iOS 18 release.\nThe discussions are still underway, and it’s unclear how the AI agreement will be branded. This would be a significant expansion of the existing relationship — default search engine — between the two companies.\nLooking at the rest of the industry, Google announced a partnership with Samsung in February to have Gemini power summarization features in the Galaxy S24’s notes and voice recording apps, as well as keyboard. Samsung is also using Imagen 2 text-to-image diffusion for a generative editing feature in the photo gallery app. Those features all require server-side processing, but Samsung is also using an on-device version of Gemini.\nGoogle offers Gemini in three sizes, with Pro being used by most first and third-party apps. Gemini 1.0 Pro powers the free version of gemini.google.com, while 1.0 Ultra is used in the paid Gemini Advanced tier.",
        "created_utc": 1710761293.0,
        "subreddit_name": "stocks",
        "comments": 152
    },
    {
        "title": "Google +900k gain",
        "score": 9423,
        "url": "https://www.reddit.com/gallery/1bhyo7a",
        "content": "Started buying Google calls after it decided it wanted to tag the 200 day(the greatest buy signal ever for big caps). Hammered some 138’s expiring 3/22 last Friday after we spent an hour around the 140 mark. Something told me it wants to continue its momo. Got lucky with that Apple/Google news. Sold everything during the morning pop around 151.  Hit a new milestone in the ol’ Robinhood this morning as well. Sold the Apple as well.",
        "created_utc": 1710788244.0,
        "subreddit_name": "wallstreetbets",
        "comments": 893
    },
    {
        "title": "Apple Is in Talks to Let Google’s Gemini Power iPhone Generative AI Features",
        "score": 1784,
        "url": "https://www.bloomberg.com/news/articles/2024-03-18/apple-in-talks-to-license-google-gemini-for-iphone-ios-18-generative-ai-tools?srnd=undefined&sref=9hGJlFio",
        "content": "",
        "created_utc": 1710740239.0,
        "subreddit_name": "apple",
        "comments": 632
    },
    {
        "title": "Apple Quietly Reveals MM1, a Multimodal LLM",
        "score": 1089,
        "url": "https://www.thurrott.com/a-i/299663/apple-quietly-reveals-mm1-a-multimodal-llm",
        "content": "",
        "created_utc": 1710732712.0,
        "subreddit_name": "apple",
        "comments": 119
    },
    {
        "title": "Apple Working on Solution for EU Core Technology Fee Possibly Bankrupting Apps That Go Unexpectedly Viral",
        "score": 630,
        "url": "https://www.macrumors.com/2024/03/18/apple-eu-core-technology-fee-viral-solution/",
        "content": "",
        "created_utc": 1710796342.0,
        "subreddit_name": "apple",
        "comments": 440
    },
    {
        "title": "Apple Jing’an to welcome its first customers this Thursday, March 21, in Shanghai",
        "score": 0,
        "url": "https://www.stocktitan.net/news/AAPL/apple-jing-an-to-welcome-its-first-customers-this-thursday-march-21-a2p2dmy73bb4.html",
        "content": "",
        "created_utc": 1710763201.0,
        "subreddit_name": "AAPL",
        "comments": 0
    }
]